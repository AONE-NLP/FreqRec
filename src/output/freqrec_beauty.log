2025-07-26 16:06:06,751 - Namespace(adam_beta1=0.9, adam_beta2=0.999, alpha=0.7, alpha_loss=0.6, attention_probs_dropout_prob=0.5, batch_size=512, checkpoint_path='output/freqrec_beauty.pt', chux='p', cuda_condition=True, data_dir='./data/', data_file='./data/Beauty.txt', data_name='Beauty', do_eval=False, epochs=300, fft_loss_type='l2', fourier_loss=True, fre=1.0, gama=0.7, gpu_id='0', hidden_act='gelu', hidden_dropout_prob=0.5, hidden_size=64, initializer_range=0.02, item_size=12102, load_model='freqrec_Beauty', log_freq=1, lr=0.0005, max_seq_length=50, model_type='freqrec', no_cuda=False, num_attention_heads=1, num_hidden_layers=2, num_items=10, num_users=22364, num_workers=4, output_dir='output/', patience=4, same_target_path='./data/Beauty_same_target.npy', seed=42, train_name='freqrec_beauty', variance=5, weight_decay=0.0)
2025-07-26 16:06:06,770 - FreqRecModel(
  (item_embeddings): Embedding(12102, 64, padding_idx=0)
  (position_embeddings): Embedding(50, 64)
  (LayerNorm): LayerNorm()
  (dropout): Dropout(p=0.5, inplace=False)
  (item_encoder): FilterEncoder(
    (blocks): ModuleList(
      (0): FilterBlock(
        (layer): FilterLayer(
          (filter_layer): Filter_Model(
            (out_dropout): Dropout(p=0.5, inplace=False)
            (LayerNorm): LayerNorm()
          )
          (attention_layer): MultiHeadAttention(
            (query): Linear(in_features=64, out_features=64, bias=True)
            (key): Linear(in_features=64, out_features=64, bias=True)
            (value): Linear(in_features=64, out_features=64, bias=True)
            (softmax): Softmax(dim=-1)
            (attn_dropout): Dropout(p=0.5, inplace=False)
            (dense): Linear(in_features=64, out_features=64, bias=True)
            (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
            (out_dropout): Dropout(p=0.5, inplace=False)
          )
        )
        (feed_forward): FeedForward(
          (dense_1): Linear(in_features=64, out_features=256, bias=True)
          (dense_2): Linear(in_features=256, out_features=64, bias=True)
          (LayerNorm): LayerNorm()
          (dropout): Dropout(p=0.5, inplace=False)
        )
      )
      (1): FilterBlock(
        (layer): FilterLayer(
          (filter_layer): Filter_Model(
            (out_dropout): Dropout(p=0.5, inplace=False)
            (LayerNorm): LayerNorm()
          )
          (attention_layer): MultiHeadAttention(
            (query): Linear(in_features=64, out_features=64, bias=True)
            (key): Linear(in_features=64, out_features=64, bias=True)
            (value): Linear(in_features=64, out_features=64, bias=True)
            (softmax): Softmax(dim=-1)
            (attn_dropout): Dropout(p=0.5, inplace=False)
            (dense): Linear(in_features=64, out_features=64, bias=True)
            (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
            (out_dropout): Dropout(p=0.5, inplace=False)
          )
        )
        (feed_forward): FeedForward(
          (dense_1): Linear(in_features=64, out_features=256, bias=True)
          (dense_2): Linear(in_features=256, out_features=64, bias=True)
          (LayerNorm): LayerNorm()
          (dropout): Dropout(p=0.5, inplace=False)
        )
      )
    )
  )
)
2025-07-26 16:06:08,062 - Total Parameters: 911488
